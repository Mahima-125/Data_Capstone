{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b90743e8-bbeb-453c-ae3c-274b3451c662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Service Principal** **Authentication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def0e37a-b8ea-4287-9ea6-0c43c9372fc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Bronze Layer - Medallion Architecture (Service Principal Auth)\n",
    "# --------------------------------\n",
    "\n",
    "\n",
    "# Retrieve Service Principal credentials securely from Azure Key Vault via Databricks secrets\n",
    "client_id = dbutils.secrets.get(scope=\"secretscope_datacapus6\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"secretscope_datacapus6\", key=\"client-secret\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"secretscope_datacapus6\", key=\"tenant-id\")\n",
    "\n",
    "\n",
    "# Define Azure Data Lake Storage account and container for Bronze layer\n",
    "storage_account = \"storageaccus6\"\n",
    "container_name = \"bronze\"\n",
    "\n",
    "\n",
    "# Configure Spark for Service Principal + OAuth\n",
    "spark.conf.set(\"fs.azure.account.auth.type\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type\",\"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id\", client_id)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret\", client_secret)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint\",f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "# Base path for Bronze layer\n",
    "abfss_path = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4ee476d9-4195-41d3-8129-8bf123bda2f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{abfss_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "676b3866-0554-4c13-b302-0d0f094da2aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Sample Reads for Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb73499c-cc66-4e86-be9c-2f508a253f9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_json_sample = spark.read.text(f\"{abfss_path}house-price-parquet.json\")\n",
    "print(\"JSON Sample: \")\n",
    "display(df_json_sample.limit(5))\n",
    "\n",
    "\n",
    "df_orders_sample = spark.read.text(f\"{abfss_path}sales_products.txt\")\n",
    "print(\"Sales Orders Sample: \")\n",
    "display(df_orders_sample.limit(5))\n",
    "\n",
    "\n",
    "df_world_sample = spark.read.text(f\"{abfss_path}population.txt\")\n",
    "print(\"World Population Sample: \")\n",
    "display(df_world_sample.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a81e4a5e-7dd0-4cb7-a6c4-20e8265bd17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ingest raw data into Bronze layer as Delta tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "750eb2da-ba38-44bc-93bf-ecd5e9fe4e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_house_bronze = spark.read.text(f\"{abfss_path}house-price-parquet.json\")\n",
    "df_house_bronze.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(f\"{abfss_path}house_price\")\n",
    "\n",
    "\n",
    "df_orders_bronze = spark.read.text(f\"{abfss_path}sales_products.txt\")\n",
    "df_orders_bronze.write.format(\"delta\").mode(\"overwrite\").save(f\"{abfss_path}sales_products\")\n",
    "\n",
    "\n",
    "df_world_bronze = spark.read.text(f\"{abfss_path}population.txt\")\n",
    "df_world_bronze.write.format(\"delta\").mode(\"overwrite\").save(f\"{abfss_path}population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55c30c8f-3a7c-417a-9fe1-ba30bcedad4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Demonstrate Delta Lake Time Travel (Versioning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b2ee72-46d9-49be-a440-e93c41a11547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history_df = spark.sql(f\"DESCRIBE HISTORY delta.`{abfss_path}sales_products`\")\n",
    "display(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb616f7-be8a-4bb1-9410-6f56a5c26dd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_house_v0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(f\"{abfss_path}house_price\")\n",
    "\n",
    "\n",
    "df_orders_old = spark.read.format(\"delta\").option(\"timestampAsOf\", \"2025-11-04T11:34:22\").load(f\"{abfss_path}sales_products\")\n",
    "\n",
    "\n",
    "print(\"House Price Data Version 0: \")\n",
    "display(df_house_v0.limit(5))\n",
    "\n",
    "\n",
    "print(\"Sales Orders Data as of 2025-11-04T11:34:22 \")\n",
    "display(df_orders_old.limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
